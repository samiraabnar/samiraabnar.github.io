---
---
References
==========

@inproceedings{Dinits1970AlgorithmFS,
  title={Algorithm for solution of a problem of maximal flow in a network with power estimation},
  author={E. A. Dinits},
  year={1970}
}


@inproceedings{bahdanau2014neural,
  title={Neural Machine Translation by Jointly Learning to Align and Translate},
  author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  booktitle={proceedings of the 2015 International Conference on
Learning Representations},
  year={2015},
}

@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={proceedings of International Conference on Machine Learning},
  pages={2048--2057},
  year={2015}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{rocktaschel2015reasoning,
  title={Reasoning about Entailment with Neural Attention},
  author={Rockt{\"a}schel, Tim and Grefenstette, Edward and Hermann, Karl Moritz and Kocisky, Tomas and Blunsom, Phil},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016}
}

@inproceedings{dehghani2018universal,
  title={Universal transformers},
  author={Dehghani, Mostafa and Gouws, Stephan and Vinyals, Oriol and Uszkoreit, Jakob and Kaiser, {\L}ukasz},
  booktitle={proceedings of the 2019 International Conference on Learning Representations},
  url={https://arxiv.org/abs/1807.03819},
  year={2019}
}

@article{chen2019improving,
  title={Improving the Interpretability of Neural Sentiment Classifiers via Data Augmentation},
  author={Chen, Hanjie and Ji, Yangfeng},
  journal={arXiv preprint arXiv:1909.04225},
  year={2019}
}

@inproceedings{serrano2019attention,
    title = "Is Attention Interpretable?",
    author = "Serrano, Sofia  and
      Smith, Noah A.",
    booktitle = "proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1282"
}

@inproceedings{wang2016attention,
  title={Attention-based LSTM for aspect-level sentiment classification},
  author={Wang, Yequan and Huang, Minlie and Zhao, Li and others},
  booktitle={proceedings of the 2016 conference on empirical methods in natural language processing},
  pages={606--615},
  year={2016}
}

@inproceedings{lee2017interactive,
  title={Interactive visualization and manipulation of attention-based neural machine translation},
  author={Lee, Jaesong and Shin, Joong-Hwi and Kim, Jun-Seok},
  booktitle={proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={121--126},
  year={2017}
}

@inproceedings{jain2019attention,
title = "{A}ttention is not {E}xplanation",
    author = "Jain, Sarthak  and
      Wallace, Byron C.",
    booktitle = "proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1357",
    doi = "10.18653/v1/N19-1357",
    pages = "3543--3556",
}


@article{pruthi2019learning,
  title={Learning to deceive with attention-based explanations},
  author={Pruthi, Danish and Gupta, Mansi and Dhingra, Bhuwan and Neubig, Graham and Lipton, Zachary C},
  journal={arXiv preprint arXiv:1909.07913},
  year={2019}
}

@article{EdmondsKarp,
 author = {Edmonds, Jack and Karp, Richard M.},
 title = {Theoretical Improvements in Algorithmic Efficiency for Network Flow Problems},
 journal = {J. ACM},
 issue_date = {April 1972},
 volume = {19},
 number = {2},
 month = apr,
 year = {1972},
 issn = {0004-5411},
 pages = {248--264},
 numpages = {17},
 url = {http://doi.acm.org/10.1145/321694.321699},
 doi = {10.1145/321694.321699},
 acmid = {321699},
 publisher = {ACM},
}

@inproceedings{wiegreffe2019attention,
    title = "Attention is not not Explanation",
    author = "Wiegreffe, Sarah  and
      Pinter, Yuval",
    booktitle = "proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1002",
}

@article{vashishth2019attention,
  title={Attention interpretability across nlp tasks},
  author={Vashishth, Shikhar and Upadhyay, Shyam and Tomar, Gaurav Singh and Faruqui, Manaal},
  journal={arXiv preprint arXiv:1909.11218},
  year={2019}
}

@article{coenen2019visualizing,
  title={Visualizing and Measuring the Geometry of BERT},
  author={Coenen, Andy and Reif, Emily and Yuan, Ann and Kim, Been and Pearce, Adam and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1906.02715},
  year={2019}
}


@article{vig2019visualizing,
  title={Visualizing Attention in Transformer-Based Language models},
  author={Vig, Jesse},
  journal={arXiv preprint arXiv:1904.02679},
  year={2019}
}


@inproceedings{brunner2019validity,
    title={On Identifiability in Transformers},
    author={Gino Brunner and Yang Liu and Damian Pascual and Oliver Richter and Massimiliano Ciaramita and Roger Wattenhofer},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=BJg1f6EFDB}
}


@incollection{montavon2019layer,
  title={Layer-wise relevance propagation: an overview},
  author={Montavon, Gr{\'e}goire and Binder, Alexander and Lapuschkin, Sebastian and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  booktitle={Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
  pages={193--209},
  year={2019},
  publisher={Springer}
}

@article{linzen2016assessing,
    Author = {Linzen, Tal and Dupoux, Emmanuel and Goldberg, Yoav},
    Journal = {Transactions of the Association for Computational Linguistics},
    Title = {Assessing the ability of {LSTMs} to learn syntax-sensitive dependencies},
    Volume = {4},
    Pages = {521--535},
    Year = {2016}
}


@article{wolf2019huggingfacests,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  year={2019}
}

@inproceedings{devlin2018bert,
 title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
}

@inbook{ancona2019,
author="Ancona, Marco
and Ceolini, Enea
and {\"O}ztireli, Cengiz
and Gross, Markus",
title="Gradient-Based Attribution Methods",
bookTitle="Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",
year="2019",
publisher="Springer International Publishing",
pages="169--191",
}

@inproceedings{alg-maxflow,
 author = {Orlin, James B.},
 title = {Max Flows in O(Nm) Time, or Better},
 booktitle = {proceedings of the Forty-fifth Annual ACM Symposium on Theory of Computing},
 series = {STOC '13},
 year = {2013},
 isbn = {978-1-4503-2029-0},
 pages = {765--774},
 numpages = {10},
 publisher = {ACM},
}

@book{clrs,
 author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
 title = {Introduction to Algorithms, Third Edition},
 year = {2009},
 isbn = {0262033844, 9780262033848},
 edition = {3rd},
 publisher = {The MIT Press},
}

@misc{sanh2019distilbert,
    title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
    author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
    year={2019},
    eprint={1910.01108},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@inproceedings{clark-etal-2019-bert,
    title = "What Does {BERT} Look at? An Analysis of {BERT}{'}s Attention",
    author = "Clark, Kevin  and
      Khandelwal, Urvashi  and
      Levy, Omer  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4828",
    doi = "10.18653/v1/W19-4828",
    pages = "276--286",
    abstract = "Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT{'}s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT{'}s attention.",
}


@inproceedings{socher-etal-2013-recursive,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D13-1170",
    pages = "1631--1642",
}

@inproceedings{wang-etal-2018-glue,
    title = "{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    author = "Wang, Alex  and
      Singh, Amanpreet  and
      Michael, Julian  and
      Hill, Felix  and
      Levy, Omer  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-5446",
    doi = "10.18653/v1/W18-5446",
    pages = "353--355",
    abstract = "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusively tailored to a specific task, genre, or dataset.",
}

@article{DBLP:journals/corr/cs-CL-0108005,
  author    = {Joshua Goodman},
  title     = {A Bit of Progress in Language Modeling},
  journal   = {CoRR},
  volume    = {cs.CL/0108005v1},
  year      = {2001},
  url       = {http://arxiv.org/abs/cs.CL/0108005v1},
  timestamp = {Wed, 07 Jun 2017 14:40:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/cs-CL-0108005},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GOODMAN2001403,
title = "A bit of progress in language modeling",
journal = "Computer Speech \& Language",
volume = "15",
number = "4",
pages = "403-434",
year = "2001",
issn = "0885-2308",
doi = "10.1006/csla.2001.0174",
OPTurl = "http://www.sciencedirect.com/science/article/pii/S0885230801901743",
author = "Joshua T. Goodman"
}

@article{DBLP:journals/corr/cs-CL-9905001,
  author    = {Rebecca Hwa},
  title     = {Supervised Grammar Induction Using Training Data with Limited Constituent Information},
  journal   = {CoRR},
  volume    = {cs.CL/9905001},
  note = {Version 1},
  year      = {1999},
  url       = {http://arxiv.org/abs/cs.CL/9905001},
  timestamp = {Wed, 07 Jun 2017 14:41:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/cs-CL-9905001},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{P99-1010,
  author =  "Hwa, Rebecca",
  title =   "Supervised Grammar Induction using Training Data with Limited Constituent Information",
  booktitle =   "Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics",
  year =    "1999",
  url =     "http://www.aclweb.org/anthology/P99-1010"
}

@book{Jurafsky+Martin:2009a,
  author    = {Jurafsky, Daniel and Martin, James H.},
  title     = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},
  publisher = {Pearson Prentice Hall},
  year      = 2009,
  edition   = {Second}
}

@inproceedings{Mueller2019WhenDL,
  title={When Does Label Smoothing Help?},
  author={Rafael Rodrigo Mueller and Simon Kornblith and Geoffrey E. Hinton},
  booktitle={Advances in Neural Information Processing Systems 32},
  year={2019},
  url={https://arxiv.org/abs/1906.02629},
  series={NeurIPS'19}
}

@article{wolpert1997no,
author = {Wolpert, D. H. and Macready, W. G.},
title = {No Free Lunch Theorems for Optimization},
year = {1997},
issue_date = {April 1997},
publisher = {IEEE Press},
volume = {1},
number = {1},
issn = {1089-778X},
url = {https://doi.org/10.1109/4235.585893},
doi = {10.1109/4235.585893},
journal = {IEEE Transactions on Evolutionary Computation},
month = apr,
pages = {67–82},
numpages = {16}
}

@techreport{mitchell1980need,
  address = {New Brunswick, NJ},
  author = {Mitchell, Tom M.},
  institution = {Rutgers University},
  title = {The Need for Biases in Learning Generalizations},
  url = {http://dml.cs.byu.edu/~cgc/docs/mldm_tools/Reading/Need for Bias.pdf},
  year = 1980
}

@article{mccoy2019berts,
  author    = {R. Thomas McCoy and
               Robert Frank and
               Tal Linzen},
  title     = {Does syntax need to grow on trees? Sources of hierarchical inductive
               bias in sequence-to-sequence networks},
  journal   = {CoRR},
  volume    = {abs/2001.03632},
  year      = {2020},
  url       = {https://arxiv.org/abs/2001.03632},
  archivePrefix = {arXiv},
  eprint    = {2001.03632},
}


@inproceedings{frankle2018lottery,
  author = {Frankle, Jonathan and Carbin, Michael},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations},
  series={ICLR'19},
  ee = {https://openreview.net/forum?id=rJl-b3RcF7},
  title = {The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks.},
  url = {http://dblp.uni-trier.de/db/conf/iclr/iclr2019.html#FrankleC19},
  year = 2019
}


@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015},
  url={https://arxiv.org/abs/1503.02531}
}

@article{linzen2016assessing,
	author = {Tal Linzen and Emmanuel Dupoux and Yoav Goldberg},
	title = {Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies},
	journal = {Transactions of the Association for Computational Linguistics},
	volume = {4},
	number = {0},
	year = {2016},
	url = {https://transacl.org/ojs/index.php/tacl/article/view/972},
	}

@inproceedings{tran-etal-2018-importance,
    title = "The Importance of Being Recurrent for Modeling Hierarchical Structure",
    author = "Tran, Ke  and
      Bisazza, Arianna  and
      Monz, Christof",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    year = "2018",
    url = "https://www.aclweb.org/anthology/D18-1503",
    series= {EMNLP'18}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019},
  url={https://arxiv.org/abs/1910.01108}
}

@inproceedings{bucilua2006model,
  title={Model compression},
  author={Buciluǎ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year={2006},
  url={https://dl.acm.org/doi/10.1145/1150402.1150464},
  series={KDD '06}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems 30},
  pages={5998--6008},
  year={2017},
  series={NeurIPS'17},
  url={https://arxiv.org/abs/1706.03762}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press},
  url={https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735}
}

@inproceedings{sutskever2013importance,
  title={On the importance of initialization and momentum in deep learning},
  author={Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  url={https://dl.acm.org/doi/10.5555/3042817.3043064},
  year={2013},
  series= {ICML'13}
}


@inproceedings{universaltrans,
  author    = {Mostafa Dehghani and
               Stephan Gouws and
               Oriol Vinyals and
               Jakob Uszkoreit and
               Lukasz Kaiser},
  title     = {Universal Transformers},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations},
  url={https://arxiv.org/abs/1807.03819},
  series={ICLR'19},
  year = {2019},
  }


@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018},
  url={https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035}
}

@inproceedings{Devlin2019BERTPO,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  url={https://arxiv.org/abs/1810.04805},
  year={2019},
  series={NAACL-HLT'19}
}

@InProceedings{Nixon_2019_CVPR_Workshops,
author = {Nixon, Jeremy and Dusenberry, Michael W. and Zhang, Linchuan and Jerfel, Ghassen and Tran, Dustin},
title = {Measuring Calibration in Deep Learning},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
year = {2019}
}

@inproceedings{calibration,
author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
title = {On Calibration of Modern Neural Networks},
year = {2017},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
series = {ICML’17},
url={https://arxiv.org/abs/1706.04599}
}

@inproceedings{Loshchilov2017SGDRSG,
  title={SGDR: Stochastic Gradient Descent with Warm Restarts},
  author={Ilya Loshchilov and Frank Hutter},
  booktitle={Proceedings of the 5th International Conference on Learning Representations},
  series={ICLR'17},
  year={2017},
  url={https://arxiv.org/abs/1608.03983}
}

@article{Kingma2014AdamAM,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2014},
  url={https://arxiv.org/pdf/1412.6980.pdf},
  volume={abs/1412.6980}
}

@inproceedings{luo2019knowledge,
  title={Knowledge amalgamation from heterogeneous networks by common feature learning},
  author={Luo, Sihui and Wang, Xinchao and Fang, Gongfan and Hu, Yao and Tao, Dapeng and Song, Mingli},
  booktitle={Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
  series={IJCAI'19},
  year={2019},
  url={https://arxiv.org/abs/1906.10546}
}


@inproceedings{kim-rush-2016-sequence,
    title = "Sequence-Level Knowledge Distillation",
    author = "Kim, Yoon  and
      Rush, Alexander M.",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    year = "2016",
    series= "EMNLP'16",
    url = "https://www.aclweb.org/anthology/D16-1139",
}


@article{Mirzadeh2019ImprovedKD,
  title={Improved Knowledge Distillation via Teacher Assistant: Bridging the Gap Between Student and Teacher},
  author={Seyed-Iman Mirzadeh and Mehrdad Farajtabar and Ang Li and Hassan Ghasemzadeh},
  journal={ArXiv},
  year={2019},
  volume={abs/1902.03393}
}


@article{Liu2019ImprovingMD,
  title={Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding},
  author={Xiaodong Liu and Pengcheng He and Weizhu Chen and Jianfeng Gao},
  journal={ArXiv},
  year={2019},
  volume={abs/1904.09482},
  url={https://arxiv.org/abs/1904.09482}
}

@article{tan2019multilingual,
  title={Multilingual neural machine translation with knowledge distillation},
  author={Tan, Xu and Ren, Yi and He, Di and Qin, Tao and Zhao, Zhou and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1902.10461},
  year={2019},
  url={https://arxiv.org/abs/1902.10461}
}

@inproceedings{Park2019RelationalKD,
  title={Relational Knowledge Distillation},
  author={Wonpyo Park and Dongju Kim and Yan Lu and Minsu Cho},
  booktitle={Proceedings of 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2019},
  series={CVPR'19},
  url={https://arxiv.org/abs/1904.05068},
}

@inproceedings{Sun2019PatientKD,
  title={Patient Knowledge Distillation for BERT Model Compression},
  author={Siqi Sun and Yu Cheng and Zhe Gan and Jingjing Liu},
  booktitle={EMNLP/IJCNLP},
  year={2019}
}

@inproceedings{sun-etal-2019-patient,
    title = "Patient Knowledge Distillation for {BERT} Model Compression",
    author = "Sun, Siqi  and
      Cheng, Yu  and
      Gan, Zhe  and
      Liu, Jingjing",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
    year = "2019",
    url = "https://www.aclweb.org/anthology/D19-1441",
    series={EMNLP-IJCNLP'19},
}

@inproceedings{Nayak2019ZeroShotKD,
  title={Zero-Shot Knowledge Distillation in Deep Networks},
  author={G K Nayak and Konda Reddy Mopuri and Vaisakh Shaj and R. Venkatesh Babu and Anirban Chakraborty},
  booktitle={Proceedings of the 36th International Conference on Machine Learning},
  year={2019}
}

@article{Tang2019DistillingTK,
  title={Distilling Task-Specific Knowledge from BERT into Simple Neural Networks},
  author={Raphael Tang and Yao Lu and Linqing Liu and Lili Mou and Olga Vechtomova and Jimmy Lin},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.12136},
  url={https://arxiv.org/abs/1903.12136}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  url={https://www.ceid.upatras.gr/webpages/faculty/zaro/teaching/alg-ds/PRESENTATIONS/PAPERS/2019-Radford-et-al_Language-Models-Are-Unsupervised-Multitask- Learners.pdf},
  year={2019}
}


@inproceedings{Frosst2017DistillingAN,
  title={Distilling a Neural Network Into a Soft Decision Tree},
  author={Nicholas Frosst and Geoffrey E. Hinton},
  booktitle={Proceedings of the First International Workshop on Comprehensibility and Explanation in AI and ML 2017 co-located with 16th International Conference of the Italian Association for Artificial Intelligence},
  year={2017},
  url={https://arxiv.org/abs/1711.09784},
}

@article{Tung2019SimilarityPreservingKD,
  title={Similarity-Preserving Knowledge Distillation},
  author={Frederick Tung and Greg Mori},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.09682},
  url={https://arxiv.org/abs/1907.09682}
}

@inproceedings{Srinivas2015DatafreePP,
  title={Data-free Parameter Pruning for Deep Neural Networks},
  author={Suraj Srinivas and R. Venkatesh Babu},
  booktitle={Proceedings of the 26th British Machine Vision Conference},
  year={2015},
  url={https://www.semanticscholar.org/paper/Data-free-Parameter-Pruning-for-Deep-Neural-Srinivas-Babu/b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d},
  series={BMVC'15}
}

@inproceedings{Furlanello2018BornAgainNN,
  title={Born-Again Neural Networks},
  author={Tommaso Furlanello and Zachary Chase Lipton and Michael Tschannen and Laurent Itti and Anima Anandkumar},
  booktitle={Proceedings of the 35th International Conference on Machine Learning},
  year={2018},
  url={https://arxiv.org/abs/1805.04770},
  series={ICML'18}
}

@inproceedings{Romero2014FitNetsHF,
  author    = {Adriana Romero and
               Nicolas Ballas and
               Samira Ebrahimi Kahou and
               Antoine Chassang and
               Carlo Gatta and
               Yoshua Bengio},
  title     = {FitNets: Hints for Thin Deep Nets},
  booktitle   = {Proceedings of the 3rd International Conference on Learning Representations},
  series={ICLR'15},
  year = {2015},
  url ={https://arxiv.org/abs/1412.6550}
}

@phdthesis{dehghaniphdthesis,
  author       = {Mostafa Dehghani},
  title        = {Learning with Imperfect Supervision for Language Understanding},
  school       = {University of Amsterdam},
  year         = 2020,
}

@inproceedings{anil2018large,
title	= {Large scale distributed neural network training through online distillation},
author	= {Rohan Anil and Gabriel Pereyra and Alexandre Tachard Passos and Robert Ormandi and George Dahl and Geoffrey Hinton},
booktitle= {Proceedings of the 6th International Conference on Learning Representations},
series={ICLR'18},
year	= {2018},
URL	= {https://openreview.net/pdf?id=rkr1UDeC-}
}



@article{huang2017like,
  title={Like what you like: Knowledge distill via neuron selectivity transfer},
  author={Huang, Zehao and Wang, Naiyan},
  journal={arXiv preprint arXiv:1707.01219},
  year={2017}
}

@article{Freitag2017EnsembleDF,
  author    = {Markus Freitag and
               Yaser Al{-}Onaizan and
               Baskaran Sankaran},
  title     = {Ensemble Distillation for Neural Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1702.01802},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.01802},
  archivePrefix = {arXiv},
  eprint    = {1702.01802},
  timestamp = {Mon, 13 Aug 2018 16:46:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/FreitagAS17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{ahn2019variational,
  title={Variational information distillation for knowledge transfer},
  author={Ahn, Sungsoo and Hu, Shell Xu and Damianou, Andreas and Lawrence, Neil D and Dai, Zhenwen},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2019},
  url={https://arxiv.org/abs/1904.05835},
  series={CVPR'19}
}

@inproceedings{maheswaranathan2019universality,
  title={Universality and individuality in neural dynamics across large populations of recurrent networks},
  author={Maheswaranathan, Niru and Williams, Alex and Golub, Matthew and Ganguli, Surya and Sussillo, David},
  booktitle={Advances in neural information processing systems 32},
  year={2019},
  series={NeurIPS'19},
  url={https://arxiv.org/abs/1907.08549}
}


@inproceedings{
michael2018on,
title={On the Information Bottleneck Theory of Deep Learning},
author={Andrew Michael Saxe and Yamini Bansal and Joel Dapello and Madhu Advani and Artemy Kolchinsky and Brendan Daniel Tracey and David Daniel Cox},
booktitle={Proceedings of the 6th International Conference on Learning Representations},
series={ICLR'18},
year={2018},
url={https://openreview.net/forum?id=ry_WPG-A-},
}


@article{laakso2000content,
  title={Content and cluster analysis: assessing representational similarity in neural systems},
  author={Laakso, Aarre and Cottrell, Garrison},
  journal={Philosophical psychology},
  volume={13},
  number={1},
  pages={47--76},
  year={2000},
  publisher={Taylor \& Francis},
  url={https://www.tandfonline.com/doi/abs/10.1080/09515080050002726}
}

@inproceedings{Zhou2019UnderstandingKD,
title={Understanding Knowledge Distillation in Non-autoregressive Machine Translation},
author={Chunting Zhou and Jiatao Gu and Graham Neubig},
booktitle={Proceedings of the 8th International Conference on Learning Representations},
series={ICLR'20},
year={2020},
url={https://openreview.net/forum?id=BygFVAEKDH}
}

@inproceedings{Gu2017NonAutoregressiveNM,
  title={Non-Autoregressive Neural Machine Translation},
  author={Jiatao Gu and James Bradbury and Caiming Xiong and Victor O. K. Li and Richard Socher},
  booktitle={Proceedings of the 6th International Conference on Learning Representations},
  series={ICLR'18},
  year={2018},
  volume={abs/1711.02281},
  url={https://arxiv.org/abs/1711.02281},
}

@inproceedings{seuncurve,
author = {Seung, H. S. and Sompolinsky, H. and Tishby, N.},
title = {Learning Curves in Large Neural Networks},
year = {1991},
booktitle = {Proceedings of the Fourth Annual Workshop on Computational Learning Theory},
series = {COLT ’91},
url={https://dl.acm.org/doi/10.5555/114836.114847}
}

@ARTICLE{biasvarnn,
author={S. {Geman} and E. {Bienenstock} and R. {Doursat}},
journal={Neural Computation},
title={Neural Networks and the Bias/Variance Dilemma},
year={1992},
volume={4},
number={1},
pages={1-58},
keywords={},
url={https://ieeexplore.ieee.org/document/6797087},
}


@phdthesis{Craven1996ExtractingCM,
author = {Craven, Mark William},
title = {Extracting Comprehensible Models from Trained Neural Networks},
year = {1996},
isbn = {0591144956},
url={https://www.biostat.wisc.edu/~craven/papers/thesis.pdf},
publisher = {The University of Wisconsin - Madison},
school={University of Wisconsin-Madison},
}

@INPROCEEDINGS{Craven95extractingcomprehensible,
    author = {Mark W. Craven and Jude W. Shavlik},
    title = {Extracting Comprehensible Concept Representations from Trained Neural Networks},
    booktitle = {In: Working Notes on the IJCAI’95 Workshop on Comprehensibility in Machine Learning},
    year = {1995},
    url={https://pdfs.semanticscholar.org/78e8/72be7330bc9c81a9c2c62368dd20811605a4.pdf}
}

@inproceedings{craventree,
author = {Craven, Mark W. and Shavlik, Jude W.},
title = {Extracting Tree-Structured Representations of Trained Networks},
year = {1995},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Advances in Neural Information Processing Systems 8},
series = {NeurIPS’95},
url={https://papers.nips.cc/paper/1152-extracting-tree-structured-representations-of-trained-networks.pdf}}

@inproceedings{liang8,
author = {Liang, Percy and Daum\'{e}, Hal and Klein, Dan},
title = {Structure Compilation: Trading Structure for Features},
year = {2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
pages = {592–599},
numpages = {8},
location = {Helsinki, Finland},
series = {ICML ’08},
url={https://cs.stanford.edu/~pliang/papers/structure-icml2008.pdf}
}

@inproceedings{Socher10learningcontinuous,
    author = {Richard Socher and Christopher D. Manning and Andrew Y. Ng},
    title = {Learning continuous phrase representations and syntactic parsing with recursive neural networks},
    booktitle = {In Proceedings of the NeurIPS'10 Deep Learning and Unsupervised Feature Learning Workshop},
    year = {2010},
    url={https://ai.stanford.edu/~ang/papers/nipsdlufl10-LearningContinuousPhraseRepresentations.pdf},
}

@inproceedings{le-zuidema-2014-inside,
    title = "The Inside-Outside Recursive Neural Network model for Dependency Parsing",
    author = "Le, Phong  and
      Zuidema, Willem",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing",
    url={https://www.aclweb.org/anthology/D14-1081.pdf},
    year = "2014",
    series={EMNLP'14},
}

@article{Elman1990FindingSI,
  title={Finding Structure in Time},
  author={Jeffrey L. Elman},
  journal={Cognitive Science},
  year={1990},
  volume={14},
  pages={179-211},
  url={https://crl.ucsd.edu/~elman/Papers/fsit.pdf},
}


@inproceedings{curric2009,
author = {Bengio, Yoshua and Louradour, J\'{e}r\^{o}me and Collobert, Ronan and Weston, Jason},
title = {Curriculum Learning},
year = {2009},
publisher = {Association for Computing Machinery},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
series = {ICML ’09},
url={https://dl.acm.org/doi/10.1145/1553374.1553380}
}

@article{keskar2019ctrl,
  title={Ctrl: A conditional transformer language model for controllable generation},
  author={Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav R and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1909.05858},
  url={https://arxiv.org/abs/1909.05858},
  year={2019}
}


@inproceedings{wright1932roles,
author = {Wright, Sewall},
title = {The roles of mutation, inbreeding, crossbreeding, and selection in evolution},
year = {1932},
booktitle = {Proceedings of the 6th international congress of genetics},
url={http://www.esp.org/books/6th-congress/facsimile/contents/6th-cong-p356-wright.pdf}
}

@article{dodge2020,
  title={Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping},
  author={Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh, and Smith, Noah},
  journal={arXiv preprint arXiv: 2002.06305},
  url={https://arxiv.org/abs/2002.06305},
  year={2020}
}

@article{mu2019mnist,
  title={Mnist-c: A robustness benchmark for computer vision},
  author={Mu, Norman and Gilmer, Justin},
  journal={arXiv preprint arXiv:1906.02337},
  year={2019}
}


@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{tang2020understanding,
  title={Understanding and Improving Knowledge Distillation},
  author={Tang, Jiaxi and Shivanna, Rakesh and Zhao, Zhe and Lin, Dong and Singh, Anima and Chi, Ed H and Jain, Sagar},
  journal={arXiv preprint arXiv:2002.03532},
  year={2020}
}

@article{yuan2019revisit,
  title={Revisit Knowledge Distillation: a Teacher-free Framework},
  author={Yuan, Li and Tay, Francis EH and Li, Guilin and Wang, Tao and Feng, Jiashi},
  journal={arXiv preprint arXiv:1909.11723},
  year={2019}
}


@article{hao2019modeling,
  title={Modeling recurrence for transformer},
  author={Hao, Jie and Wang, Xing and Yang, Baosong and Wang, Longyue and Zhang, Jinfeng and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:1904.03092},
  year={2019}
}

@article{Hahn-2019-arxiv,
author = {Hahn, Michael},
title = {Theoretical Limitations of Self-Attention in Neural Sequence Models},
journal = {Transactions of the Association for Computational Linguistics},
volume = {8},
year = {2020}
}

@article{goodfellow2013maxout,
  title={Maxout networks},
  author={Goodfellow, Ian J and Warde-Farley, David and Mirza, Mehdi and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1302.4389},
  year={2013}
}

@inproceedings{cohen2016expressive,
  title={On the expressive power of deep learning: A tensor analysis},
  author={Cohen, Nadav and Sharir, Or and Shashua, Amnon},
  booktitle={Conference on Learning Theory},
  pages={698--728},
  year={2016}
}


@article{repsimlaakso2000,
author = { Aarre   Laakso  and  Garrison   Cottrell },
title = {Content and cluster analysis: Assessing representational similarity in neural systems},
journal = {Philosophical Psychology},
volume = {13},
number = {1},
pages = {47-76},
year  = {2000},
publisher = {Routledge},
doi = {10.1080/09515080050002726},
URL = {https://doi.org/10.1080/09515080050002726},
eprint = {https://doi.org/10.1080/09515080050002726}
}


@inproceedings{naeini2015obtaining,
  title={Obtaining well calibrated probabilities using bayesian binning},
  author={Naeini, Mahdi Pakdaman and Cooper, Gregory and Hauskrecht, Milos},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}

@article{degroot1983comparison,
  title={The comparison and evaluation of forecasters},
  author={DeGroot, Morris H and Fienberg, Stephen E},
  journal={Journal of the Royal Statistical Society: Series D (The Statistician)},
  year={1983},
}

@article{mobahi2020self,
  title={Self-distillation amplifies regularization in hilbert space},
  author={Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2002.05715},
  year={2020}
}
